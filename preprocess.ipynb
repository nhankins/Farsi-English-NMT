{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data\n",
    "\n",
    "#num_lines = sum(1 for line in open('mizan_en.txt'))\n",
    "#Confirm they match\n",
    "#num_lines2 = sum(1 for line in open('mizan_fa.txt'))\n",
    "#print(num_lines)\n",
    "#print(num_lines2)\n",
    "\n",
    "#Verify sizes\n",
    "#train_num = round(num_lines * .8)\n",
    "#print(train_num)\n",
    "#test_num = round(num_lines * .1)\n",
    "#print(test_num)\n",
    "#val_num = round(num_lines * .1)\n",
    "#print(val_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting with numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "en_data = pd.read_csv('og-parallel-corpus/mizan_en.txt', sep='\\t',lineterminator='\\r', header=None)\n",
    "\n",
    "#converts to numpy array format\n",
    "en_numpy_data = en_data.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffles and gives random seed\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(en_numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = en_numpy_data.shape[0]\n",
    "data_npy1 = en_numpy_data[:int(num_rows*.8)]\n",
    "data_npy2 = en_numpy_data[int(num_rows*.8): int(num_rows*.9)]\n",
    "data_npy3 = en_numpy_data[int(num_rows*.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('en_train.npy', data_npy1)\n",
    "np.save('en_test.npy', data_npy2)\n",
    "np.save('en_val.npy', data_npy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now for Persian/farsi data\n",
    "\n",
    "fa_data = pd.read_csv('og-parallel-corpus/mizan_fa.txt', sep='\\t',lineterminator='\\r', header=None)\n",
    "\n",
    "#converts to numpy array format\n",
    "fa_numpy_data = fa_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "np.random.shuffle(fa_numpy_data)\n",
    "\n",
    "num_rows1 = fa_numpy_data.shape[0]\n",
    "data_npy11 = fa_numpy_data[:int(num_rows1*.8)]\n",
    "data_npy22 = fa_numpy_data[int(num_rows1*.8): int(num_rows1*.9)]\n",
    "data_npy33 = fa_numpy_data[int(num_rows1*.9):]\n",
    "\n",
    "np.save('fa_train.npy', data_npy11)\n",
    "np.save('fa_test.npy', data_npy22)\n",
    "np.save('fa_val.npy', data_npy33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert npy files back to text\n",
    "\n",
    "conv_en_train = np.load('en_train.npy', allow_pickle=True)\n",
    "conv_en_train = np.squeeze(conv_en_train)\n",
    "np.savetxt('en_train.txt',conv_en_train, fmt='%s')\n",
    "\n",
    "#This saves the text to a file but skips a line, so run this in terminal for each:\n",
    "#grep -v '^$' file.txt > no_empty_lines.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The rest of the files\n",
    "conv_en_test = np.load('en_test.npy', allow_pickle=True)\n",
    "conv_en_test = np.squeeze(conv_en_test)\n",
    "np.savetxt('pre-en_test.txt',conv_en_test, fmt='%s')\n",
    "\n",
    "conv_en_val = np.load('en_val.npy', allow_pickle=True)\n",
    "conv_en_val = np.squeeze(conv_en_val)\n",
    "np.savetxt('pre-en_val.txt',conv_en_val, fmt='%s')\n",
    "\n",
    "conv_fa_train = np.load('fa_train.npy', allow_pickle=True)\n",
    "conv_fa_train = np.squeeze(conv_fa_train)\n",
    "np.savetxt('pre-fa_train.txt',conv_fa_train, fmt='%s')\n",
    "\n",
    "conv_fa_test = np.load('fa_test.npy', allow_pickle=True)\n",
    "conv_fa_test = np.squeeze(conv_fa_test)\n",
    "np.savetxt('pre-fa_test.txt',conv_fa_test, fmt='%s')\n",
    "\n",
    "conv_fa_val = np.load('fa_val.npy', allow_pickle=True)\n",
    "conv_fa_val = np.squeeze(conv_fa_val)\n",
    "np.savetxt('pre-fa_val.txt',conv_fa_val, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to do it without randomizing for NMT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "en_data_2 = pd.read_csv('og-parallel-corpus/mizan_en.txt', sep='\\t',lineterminator='\\r', header=None)\n",
    "\n",
    "#converts to numpy array format\n",
    "en_numpy_data_2 = en_data_2.values\n",
    "\n",
    "num_rows_2 = en_numpy_data_2.shape[0]\n",
    "no_rand_data1 = en_numpy_data_2[:int(num_rows_2*.8)]\n",
    "no_rand_data2 = en_numpy_data_2[int(num_rows_2*.8): int(num_rows_2*.9)]\n",
    "no_rand_data3 = en_numpy_data_2[int(num_rows_2*.9):]\n",
    "\n",
    "np.save('en_train.npy', no_rand_data1)\n",
    "np.save('en_test.npy', no_rand_data2)\n",
    "np.save('en_val.npy', no_rand_data3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_en_train_2 = np.load('en_train.npy', allow_pickle=True)\n",
    "conv_en_train_2 = np.squeeze(conv_en_train_2)\n",
    "np.savetxt('pre-en_train.txt',conv_en_train_2, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_en_test_2 = np.load('en_test.npy', allow_pickle=True)\n",
    "conv_en_test_2 = np.squeeze(conv_en_test_2)\n",
    "np.savetxt('pre-en_test.txt',conv_en_test_2, fmt='%s')\n",
    "\n",
    "conv_en_val_2 = np.load('en_val.npy', allow_pickle=True)\n",
    "conv_en_val_2 = np.squeeze(conv_en_val_2)\n",
    "np.savetxt('pre-en_val.txt',conv_en_val_2, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_data_2 = pd.read_csv('og-parallel-corpus/mizan_fa.txt', sep='\\t',lineterminator='\\r', header=None)\n",
    "\n",
    "#converts to numpy array format\n",
    "fa_numpy_data_2 = fa_data_2.values\n",
    "\n",
    "num_rows_22 = fa_numpy_data_2.shape[0]\n",
    "no_rand_data11 = fa_numpy_data_2[:int(num_rows_22*.8)]\n",
    "no_rand_data22 = fa_numpy_data_2[int(num_rows_22*.8): int(num_rows_22*.9)]\n",
    "no_rand_data33 = fa_numpy_data_2[int(num_rows_22*.9):]\n",
    "\n",
    "np.save('fa_train.npy', no_rand_data11)\n",
    "np.save('fa_test.npy', no_rand_data22)\n",
    "np.save('fa_val.npy', no_rand_data33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fa_train_2 = np.load('fa_train.npy', allow_pickle=True)\n",
    "conv_fa_train_2 = np.squeeze(conv_fa_train_2)\n",
    "np.savetxt('pre-fa_train.txt',conv_fa_train_2, fmt='%s')\n",
    "\n",
    "conv_fa_test_2 = np.load('fa_test.npy', allow_pickle=True)\n",
    "conv_fa_test_2 = np.squeeze(conv_fa_test_2)\n",
    "np.savetxt('pre-fa_test.txt',conv_fa_test_2, fmt='%s')\n",
    "\n",
    "conv_fa_val_2 = np.load('fa_val.npy', allow_pickle=True)\n",
    "conv_fa_val_2 = np.squeeze(conv_fa_val_2)\n",
    "np.savetxt('pre-fa_val.txt',conv_fa_val_2, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64c120a508f6324c92d6f1d97e909913af50a4f06219c1d418241b2f1bcce404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
